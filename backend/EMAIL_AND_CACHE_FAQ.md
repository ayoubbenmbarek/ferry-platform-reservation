# Email & Cache FAQ

## Question 1: When are confirmation emails sent?

### **Answer: Emails are sent ASYNCHRONOUSLY by dedicated workers**

### Booking Confirmation Email Flow:

```
User completes booking â†’ Returns response immediately
                      â†“
              Queue email task (< 100ms)
                      â†“
          Email worker picks up task (1-3 seconds)
                      â†“
            Send email via SMTP (2-5 seconds)
                      â†“
        User receives email (5-15 seconds total)
```

### Cancellation Email Flow (Asynchronous with Listener):

**âœ… YES - Cancellation emails work asynchronously with listeners!**

```
User/Admin cancels booking
        â†“
API updates database (status = CANCELLED, refund created)
        â†“
API returns 200 OK immediately (< 2 seconds)
        â†“
Queue cancellation email task â†’ Goes to "emails" queue
        â†“
EMAIL WORKER (Listener) picks up task
        â†“
Sends cancellation email with refund details
        â†“
User receives email (5-15 seconds after cancellation)
```

**Key Point**: The API doesn't wait for the email. The email worker acts as a "listener" that processes queued tasks independently.

### Payment Success Email Flow (Webhook + Worker):

```
Stripe Payment Success
        â†“
Stripe sends webhook to /webhooks/stripe
        â†“
Webhook endpoint queues payment task â†’ Returns 200 immediately
        â†“
PAYMENT WORKER processes webhook (2-5 seconds)
        â†“
Updates payment.status = COMPLETED
Updates booking.status = CONFIRMED
        â†“
Queues email task â†’ Goes to "emails" queue
        â†“
EMAIL WORKER sends payment confirmation
        â†“
User receives email (10-20 seconds after payment)
```

### Refund Confirmation Email:

```
Admin/User refunds booking
        â†“
Stripe refund created
        â†“
API returns response immediately
        â†“
Queue refund email task
        â†“
EMAIL WORKER sends refund confirmation
        â†“
User receives email (5-15 seconds)
```

### Timeline Summary:

| Event | API Response Time | Email Delivery Time | Total Time |
|-------|-------------------|---------------------|------------|
| Booking Created | < 1 second | 5-15 seconds | 5-15 seconds |
| Payment Success | < 1 second (webhook) | 10-20 seconds | 10-20 seconds |
| Cancellation | < 2 seconds | 5-15 seconds | 7-17 seconds |
| Refund | < 2 seconds | 5-15 seconds | 7-17 seconds |

**Benefits:**
- âœ… Fast API responses (don't wait for email)
- âœ… Automatic retries if email fails
- âœ… Can scale email workers independently
- âœ… User experience not affected by slow SMTP servers

---

## Question 2: When is cache updated/invalidated?

### **Answer: Cache is invalidated on specific events + auto-expires**

### Cache Strategy:

#### 1. **Ferry Search Results** (TTL: 5 minutes)

**When Cached:**
```python
# User searches for ferries
GET /api/v1/ferry/search?from=tunis&to=marseille&date=2025-12-25

# Check cache first
cached = cache_service.get_ferry_search(search_params)
if cached:
    return cached  # âš¡ Fast response (< 50ms)

# Cache miss - fetch from operators
results = await ferry_service.search(search_params)

# Cache for 5 minutes
cache_service.set_ferry_search(search_params, results, ttl=300)
```

**When Invalidated:**
- â±ï¸ **Auto-expires after 5 minutes** (TTL)
- ğŸ”„ **After booking confirmed** (capacity changed)
- âŒ **After booking cancelled** (capacity increased)
- ğŸ› ï¸ **Admin updates prices/schedules** (manual clear)

**Example:**
```
10:00:00 - User searches Tunisâ†’Marseille (cache MISS, stores result)
10:02:00 - Another user searches same route (cache HIT âœ…, returns instantly)
10:03:00 - Someone books this ferry â†’ Invalidate cache
10:03:01 - Next search (cache MISS, fetches fresh data with updated capacity)
10:05:00 - Cache auto-expires (TTL reached)
```

#### 2. **Availability Data** (TTL: 1 minute)

**When Cached:**
```python
# Before payment, check real-time availability
availability = cache_service.get_availability(sailing_id)

if not availability:
    # Cache miss - check with operator
    availability = await check_ferry_availability_task.apply_async(...).get()
    cache_service.set_availability(sailing_id, availability, ttl=60)
```

**When Invalidated:**
- â±ï¸ **Auto-expires after 1 minute** (shorter TTL for real-time data)
- ğŸ“ **After booking confirmed** â†’ `invalidate_sailing_availability(sailing_id)`
- âŒ **After booking cancelled** â†’ `invalidate_sailing_availability(sailing_id)`

#### 3. **Route-Specific Invalidation**

```python
# When admin updates ferry schedule or prices for a route
cache_service.invalidate_route_searches("tunis", "marseille")
# Clears all cached searches for Tunis â†’ Marseille
```

### Cache Invalidation in Code:

#### After Booking Confirmed:

```python
# In payment webhook task (payment_tasks.py)
async def process_payment_webhook_task(...):
    # Update booking status
    booking.status = BookingStatusEnum.CONFIRMED
    db.commit()

    # Invalidate cache for this sailing
    cache_service.invalidate_sailing_availability(booking.sailing_id)

    # Also invalidate search results for this route
    cache_service.invalidate_route_searches(
        booking.departure_port,
        booking.arrival_port
    )
```

#### After Cancellation:

```python
# In cancellation endpoint (bookings.py)
@router.post("/{booking_id}/cancel")
async def cancel_booking(...):
    # Process cancellation
    booking.status = BookingStatusEnum.CANCELLED
    db.commit()

    # Invalidate availability cache (ferry now has more seats)
    cache_service.invalidate_sailing_availability(booking.sailing_id)

    # Optionally invalidate route searches
    cache_service.invalidate_route_searches(
        booking.departure_port,
        booking.arrival_port
    )

    # Queue cancellation email (async)
    send_cancellation_email_task.delay(...)
```

### Cache Hit Rate Expectations:

| Scenario | Expected Hit Rate | Benefit |
|----------|------------------|---------|
| Popular routes (Tunisâ†”Marseille) | 70-90% | Most searches return instantly |
| Same user searches twice | 100% (if < 5 min) | Instant results |
| After booking confirmed | 0% (cache invalidated) | Fresh data with updated capacity |
| Off-peak routes | 20-40% | Less traffic, fewer hits |
| Admin price update | 0% (cache cleared) | All users get new prices |

### Cache Performance Metrics:

```
Cache HIT:  ğŸš€ Response time: 30-100ms
Cache MISS: ğŸŒ Response time: 500-2000ms (API calls)

Speed improvement: 10-50x faster!
```

### Visual Timeline:

```
User A searches â†’ Cache MISS â†’ Fetch from API (1500ms) â†’ Cache result
      â†“ (0:00)
User B searches (same route) â†’ Cache HIT â†’ Return instantly (50ms) âœ…
      â†“ (2:30)
User C books ferry â†’ Payment success â†’ Invalidate cache ğŸ—‘ï¸
      â†“ (2:35)
User D searches â†’ Cache MISS â†’ Fetch fresh data (1200ms) â†’ Cache result
      â†“ (5:00 - TTL expired)
User E searches â†’ Cache MISS â†’ Auto-refresh â†’ Cache result
```

---

## Monitoring Cache Performance

### Check Cache Stats:

```bash
# Redis CLI
redis-cli

# Check cache keys
> KEYS ferry_search:*
> KEYS availability:*

# Check cache size
> DBSIZE

# Check memory usage
> INFO memory

# Monitor cache hits/misses
> INFO stats
```

### Python Code to Monitor:

```python
from app.services.cache_service import cache_service

# Check if Redis is available
if cache_service.is_available():
    print("âœ… Redis connected")
else:
    print("âŒ Redis offline - caching disabled")

# Clear all searches (maintenance)
deleted = cache_service.clear_all_ferry_searches()
print(f"Cleared {deleted} cache entries")
```

---

## Summary

### Email Delivery:
- âœ… **Asynchronous** - API returns immediately
- âœ… **Reliable** - Automatic retries on failure
- âœ… **Fast** - 5-20 seconds delivery time
- âœ… **Scalable** - Workers can be scaled independently

### Cache Updates:
- â±ï¸ **Auto-expire**: 5 min (searches), 1 min (availability)
- ğŸ“ **On booking**: Invalidate sailing availability + route searches
- âŒ **On cancel**: Invalidate sailing availability + route searches
- ğŸ› ï¸ **Admin action**: Manual cache clear for price/schedule updates

### Benefits:
- ğŸš€ 10-50x faster search responses (with cache hits)
- ğŸ“§ Non-blocking email delivery
- ğŸ”„ Always fresh data when capacity changes
- ğŸ’ª Scalable architecture for high traffic
